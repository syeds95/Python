```python
# hme_key_metrics.py
# Full Patient-Level & Aggregate Behavior Analysis for HME Business
# Writes outputs directly into pre-created Snowflake tables and per-group rollups/views

from snowflake.snowpark import Session, Window, DataFrame as SnowparkDataFrame
from snowflake.snowpark import functions as F
from datetime import date
import os

# 1. Connect to Snowflake
tmp = {
    'account': os.getenv('SNOWFLAKE_ACCOUNT'),
    'user': os.getenv('SNOWFLAKE_USER'),
    'password': os.getenv('SNOWFLAKE_PASSWORD'),
    'role': os.getenv('SNOWFLAKE_ROLE', 'PUBLIC'),
    'warehouse': os.getenv('SNOWFLAKE_WAREHOUSE'),
    'database': os.getenv('SNOWFLAKE_DATABASE'),
    'schema': os.getenv('SNOWFLAKE_SCHEMA')
}
session = Session.builder.configs(tmp).create()

# 2. Load source data from your Snowpark DataFrame (my_df)
if not isinstance(my_df, SnowparkDataFrame):
    orders = session.create_dataframe(my_df)
else:
    orders = my_df

# 3. Reference date for recency and tenure calculations
today = date.today()

# 4. Compute descriptive patient attributes
first_order = orders.group_by("PATIENTID").agg(
    F.min("SERVICEDATEOFORDER").alias("FIRST_SERVICE_DATE")
)
last_order = orders.group_by("PATIENTID").agg(
    F.max("SERVICEDATEOFORDER").alias("LAST_SERVICE_DATE")
)

freq_amt = orders.group_by("PATIENTID").agg(
    F.count("ORDERNUMBER").alias("ORDERS_TOTAL"),
    F.sum("TOTALAMOUNT").alias("TOTAL_REVENUE"),
    F.sum("TOTALQTY").alias("TOTAL_QTY")
)

# static attributes: most recent row per patient
attr_window = Window.partition_by("PATIENTID").order_by(F.col("SERVICEDATEOFORDER").desc())
patient_attrs = (
    orders
    .with_column("rn", F.row_number().over(attr_window))
    .filter(F.col("rn") == 1)
    .select("PATIENTID", "INSURANCE", "PATIENT_GROUP", "ITEM_GROUP")
)

descriptive = (
    first_order
    .join(last_order, on="PATIENTID")
    .join(freq_amt, on="PATIENTID", how="left")
    .join(patient_attrs, on="PATIENTID", how="left")
    .with_column(
        "TENURE_DAYS",
        F.datediff('day', F.col("FIRST_SERVICE_DATE"), F.lit(today))
    )
    .with_column(
        "RECENCY_DAYS",
        F.datediff('day', F.col("LAST_SERVICE_DATE"),  F.lit(today))
    )
    .na.fill({"ORDERS_TOTAL": 0, "TOTAL_REVENUE": 0, "TOTAL_QTY": 0})
)

# 5. Compute inter-order lag and corrected on-time metrics
lag_window = Window.partition_by("PATIENTID").order_by("SERVICEDATEOFORDER")
intervals = (
    orders
    .select(
        "PATIENTID", "ORDERNUMBER", "HCPCS", "SERVICEDATEOFORDER",
        "ELIGIBLETOSHIP", "SUPPLYDURATION", "TOTALAMOUNT"
    )
    .with_column("PREV_SERVICE_DATE", F.lag("SERVICEDATEOFORDER").over(lag_window))
    .with_column(
        "DAYS_BETWEEN_ORDERS",
        F.datediff('day', F.col("PREV_SERVICE_DATE"), F.col("SERVICEDATEOFORDER"))
    )
    .filter(F.col("PREV_SERVICE_DATE").is_not_null())
    .with_column(
        "DAYS_AFTER_ELIGIBLE",
        F.datediff('day', F.col("ELIGIBLETOSHIP"), F.col("SERVICEDATEOFORDER"))
    )
    .with_column(
        "ON_TIME_FLAG",
        F.when(
            (F.col("DAYS_AFTER_ELIGIBLE") >= 0) &
            (F.col("DAYS_AFTER_ELIGIBLE") <= (F.col("SUPPLYDURATION") * 0.1)),
            1
        ).otherwise(0)
    )
)

# 6. Patient-level Aggregations
df_patient_metrics = (
    descriptive.join(
        intervals.group_by("PATIENTID").agg(
            F.avg("DAYS_BETWEEN_ORDERS").alias("AVG_DAYS_BETWEEN"),
            F.avg(
                F.when(F.col("DAYS_AFTER_ELIGIBLE") > 0, F.col("DAYS_AFTER_ELIGIBLE")).otherwise(F.lit(0))
            ).alias("AVG_DAYS_LATE"),
            F.sum("ON_TIME_FLAG").alias("ON_TIME_ORDERS"),
            F.count("ORDERNUMBER").alias("TOTAL_ORDERS"),
            F.sum("TOTALAMOUNT").alias("TOTAL_REVENUE_ORDERS")
        ), on="PATIENTID", how="left"
    )
    .with_column(
        "ON_TIME_RATE",
        F.col("ON_TIME_ORDERS") / F.col("TOTAL_ORDERS")
    )
    .select(
        "PATIENTID", "INSURANCE", "PATIENT_GROUP", "ITEM_GROUP",
        "TENURE_DAYS", "RECENCY_DAYS", "ORDERS_TOTAL", "TOTAL_REVENUE", "TOTAL_QTY",
        "AVG_DAYS_BETWEEN", "AVG_DAYS_LATE", "ON_TIME_RATE"
    )
)

# 7. Roll-up Summary across all patients
df_rollup_all = (
    df_patient_metrics.agg(
        F.avg("TENURE_DAYS").alias("AVG_TENURE_DAYS"),
        F.avg("RECENCY_DAYS").alias("AVG_RECENCY_DAYS"),
        F.avg("ORDERS_TOTAL").alias("AVG_FREQ_PER_PATIENT"),
        F.avg("TOTAL_REVENUE").alias("AVG_REV_PER_PATIENT"),
        F.avg("AVG_DAYS_BETWEEN").alias("AVG_DAYS_BETWEEN_ORDERS"),
        F.avg("AVG_DAYS_LATE").alias("AVG_DAYS_LATE"),
        F.avg("ON_TIME_RATE").alias("AVG_ON_TIME_RATE"),
    )
)

# 8. Roll-up by ITEM_GROUP, PATIENT_GROUP, and INSURANCE
#    independent roll-ups for each group
groupings = ["ITEM_GROUP", "PATIENT_GROUP", "INSURANCE"]
rollup_by = {}
for grp in groupings:
    rollup_by[grp] = (
        df_patient_metrics
        .group_by(grp)
        .agg(
            F.avg("TENURE_DAYS").alias("AVG_TENURE_DAYS"),
            F.avg("RECENCY_DAYS").alias("AVG_RECENCY_DAYS"),
            F.avg("ORDERS_TOTAL").alias("AVG_FREQ_PER_PATIENT"),
            F.avg("TOTAL_REVENUE").alias("AVG_REV_PER_PATIENT"),
            F.avg("AVG_DAYS_BETWEEN").alias("AVG_DAYS_BETWEEN_ORDERS"),
            F.avg("AVG_DAYS_LATE").alias("AVG_DAYS_LATE"),
            F.avg("ON_TIME_RATE").alias("AVG_ON_TIME_RATE")
        )
    )

# 9. Truncate existing tables
session.sql("TRUNCATE TABLE PATIENT_BEHAVIOR_METRICS").collect()
session.sql("TRUNCATE TABLE PATIENT_METRICS_ROLLUP").collect()
# Truncate intermediate roll-up views/tables if needed
for grp in groupings:
    session.sql(f"TRUNCATE TABLE ROLLUP_{grp}").collect()

# 10. Write results to Snowflake tables
#    Base tables
df_patient_metrics.write.save_as_table("PATIENT_BEHAVIOR_METRICS", mode="overwrite")
df_rollup_all.write.save_as_table("PATIENT_METRICS_ROLLUP", mode="overwrite")
#    Per-group rollups
def write_rollup(name, df):
    df.write.save_as_table(f"ROLLUP_{name}", mode="overwrite")
for grp, df in rollup_by.items():
    write_rollup(grp, df)

# 11. Optionally create views in Snowflake for each rollup
for grp in groupings:
    session.sql(f"CREATE OR REPLACE VIEW VW_ROLLUP_{grp} AS SELECT * FROM ROLLUP_{grp}").collect()

# 12. Close session
session.close()
```
