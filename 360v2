```python
# hme_key_metrics.py
# Complete Patient-Level & Aggregate Behavior Analysis for HME Business
# Revised to correctly reference descriptive fields and compute all metrics

from snowflake.snowpark import Session, Window, DataFrame as SnowparkDataFrame
from snowflake.snowpark import functions as F
from datetime import date, timedelta
import os

# 1. Connect to Snowflake
def create_session():
    conn_params = {
        'account': os.getenv('SNOWFLAKE_ACCOUNT'),
        'user': os.getenv('SNOWFLAKE_USER'),
        'password': os.getenv('SNOWFLAKE_PASSWORD'),
        'role': os.getenv('SNOWFLAKE_ROLE', 'PUBLIC'),
        'warehouse': os.getenv('SNOWFLAKE_WAREHOUSE'),
        'database': os.getenv('SNOWFLAKE_DATABASE'),
        'schema': os.getenv('SNOWFLAKE_SCHEMA')
    }
    return Session.builder.configs(conn_params).create()

session = create_session()

# 2. Load the source DataFrame
if not isinstance(my_df, SnowparkDataFrame):
    orders = session.create_dataframe(my_df)
else:
    orders = my_df

# 3. Reference date
today = date.today()

# 4. Build descriptive table: RFM + tenure + static attrs
win_desc = Window.partition_by("PATIENTID").order_by(F.col("SERVICEDATEOFORDER").desc())
descriptive = (
    orders
    .group_by("PATIENTID").agg(
        F.min("SERVICEDATEOFORDER").alias("FIRST_SERVICE_DATE"),
        F.max("SERVICEDATEOFORDER").alias("LAST_SERVICE_DATE"),
        F.count_distinct("ORDERNUMBER").alias("ORDERS_TOTAL"),
        F.sum("TOTALAMOUNT").alias("TOTAL_REVENUE"),
        F.sum("TOTALQTY").alias("TOTAL_QTY")
    )
    .join(
        orders.with_column("rn", F.row_number().over(win_desc))
              .filter(F.col("rn") == 1)
              .select("PATIENTID", "INSURANCE", "PATIENT_GROUP", "ITEM_GROUP"),
        on="PATIENTID", how="left"
    )
    .with_column("TENURE_DAYS", F.datediff('day', F.col("FIRST_SERVICE_DATE"), F.lit(today)))
    .with_column("RECENCY_DAYS", F.datediff('day', F.col("LAST_SERVICE_DATE"), F.lit(today)))
)

# 5. Deduplicate orders to one row per order
orders_dedup = (
    orders
    .select("PATIENTID", "ORDERNUMBER", "SERVICEDATEOFORDER", "ELIGIBLETOSHIP", "SUPPLYDURATION", "TOTALAMOUNT")
    .distinct()
)

# 6. Compute order-level lag and on-time flags
win_ord = Window.partition_by("PATIENTID").order_by("SERVICEDATEOFORDER")
order_intervals = (
    orders_dedup
    .with_column("PREV_DATE", F.lag("SERVICEDATEOFORDER").over(win_ord))
    .with_column("PREV_ELIGIBLE", F.lag("ELIGIBLETOSHIP").over(win_ord))
    .filter(F.col("PREV_DATE").is_not_null())
    .with_column("DAYS_BETWEEN", F.datediff('day', F.col("PREV_DATE"), F.col("SERVICEDATEOFORDER")))
    .with_column("DAYS_AFTER_ELIGIBLE", F.datediff('day', F.col("PREV_ELIGIBLE"), F.col("SERVICEDATEOFORDER")))
    .with_column("ON_TIME_FLAG",
        F.when(
            (F.col("DAYS_AFTER_ELIGIBLE") >= 0) &
            (F.col("DAYS_AFTER_ELIGIBLE") <= F.col("SUPPLYDURATION") * 0.1),
            1
        ).otherwise(0)
    )
)
order_metrics = (
    order_intervals
    .group_by("PATIENTID").agg(
        F.avg("DAYS_BETWEEN").alias("AVG_DAYS_BETWEEN"),
        F.avg(F.when(F.col("DAYS_AFTER_ELIGIBLE") > 0, F.col("DAYS_AFTER_ELIGIBLE")).otherwise(0)).alias("AVG_DAYS_LATE"),
        F.sum("ON_TIME_FLAG").alias("ON_TIME_ORDERS"),
        F.count("ORDERNUMBER").alias("TOTAL_ORDERS"),
        F.sum("TOTALAMOUNT").alias("REVENUE_ORDERS")
    )
)

# 7. Churn flag based on last supply duration
last_supply = orders_dedup.group_by("PATIENTID").agg(F.max("SUPPLYDURATION").alias("LAST_SUPPLY_DURATION"))
churn = (
    descriptive
    .join(last_supply, on="PATIENTID")
    .with_column("CHURN_FLAG",
        F.when(F.col("RECENCY_DAYS") > F.col("LAST_SUPPLY_DURATION") * 1.1, 1).otherwise(0)
    )
)

# 8. Time to first reorder (days)
second_order = (
    orders_dedup
    .with_column("rn", F.row_number().over(win_ord))
    .filter(F.col("rn") == 2)
    .select("PATIENTID", F.col("SERVICEDATEOFORDER").alias("SECOND_DATE"))
)
time_to_first = (
    descriptive
    .join(second_order, on="PATIENTID", how="left")
    .with_column("TIME_TO_FIRST_REORDER", F.datediff('day', F.col("FIRST_SERVICE_DATE"), F.col("SECOND_DATE")))
)

# 9. Prepare for LTV calculation: join FIRST_SERVICE_DATE to each order
orders_with_first = (
    orders
    .join(descriptive.select("PATIENTID", "FIRST_SERVICE_DATE"), on="PATIENTID", how="left")
    .select("PATIENTID", "FIRST_SERVICE_DATE", "SERVICEDATEOFORDER", "TOTALAMOUNT")
)

# 10. LTV curves at day thresholds: sum revenue up to days since first order
ltv_thresholds = [30, 60, 90, 180, 365]
ltv = orders_with_first
for d in ltv_thresholds:
    ltv = ltv.with_column(
        f"LTV_{d}d",
        F.when(
            F.datediff('day', F.col("FIRST_SERVICE_DATE"), F.col("SERVICEDATEOFORDER")) <= d,
            F.col("TOTALAMOUNT")
        ).otherwise(0)
    )
# Aggregate by PATIENTID
ltv = (
    ltv.group_by("PATIENTID").agg(
        *[F.sum(f"LTV_{d}d").alias(f"LTV_{d}d") for d in ltv_thresholds]
    )
)

ltv_thresholds = [30, 60, 90, 180, 365]
ltv = (
    orders_with_first
    .select(
        "PATIENTID",
        *[
            F.sum(
                F.when(
                    F.datediff('day', F.col("FIRST_SERVICE_DATE"), F.col("SERVICEDATEOFORDER")) <= d,
                    F.col("TOTALAMOUNT")
                ).otherwise(0)
            ).alias(f"LTV_{d}d")
            for d in ltv_thresholds
        ]
    )
    .group_by("PATIENTID").agg(*[F.max(f"LTV_{d}d").alias(f"LTV_{d}d") for d in ltv_thresholds])
)

# 11. Basket composition: unique HCPCS count
distinct_items = orders.group_by("PATIENTID").agg(F.count_distinct("HCPCS").alias("UNIQUE_HCPCS"))

# 12. Seasonality: distinct active months
distinct_months = (
    orders
    .with_column("MONTH", F.date_trunc("month", F.col("SERVICEDATEOFORDER")))
    .group_by("PATIENTID").agg(F.count_distinct("MONTH").alias("ACTIVE_MONTHS"))
)

# 13. Assemble full patient-level table
df_patient = (
    descriptive
    .join(order_metrics, on="PATIENTID", how="left")
    .join(churn.select("PATIENTID","CHURN_FLAG"), on="PATIENTID", how="left")
    .join(time_to_first.select("PATIENTID","TIME_TO_FIRST_REORDER"), on="PATIENTID", how="left")
    .join(ltv, on="PATIENTID", how="left")
    .join(distinct_items, on="PATIENTID", how="left")
    .join(distinct_months, on="PATIENTID", how="left")
    .with_column("ON_TIME_RATE", F.col("ON_TIME_ORDERS") / F.col("TOTAL_ORDERS"))
    .with_column(
        "DAYS_LATE_BUCKET",
        F.when(F.col("AVG_DAYS_LATE") <= 3, "0-3 days late")
         .when(F.col("AVG_DAYS_LATE") <= 7, "4-7 days late")
         .when(F.col("AVG_DAYS_LATE") <= 14, "8-14 days late")
         .when(F.col("AVG_DAYS_LATE") <= 30, "15-30 days late")
         .when(F.col("AVG_DAYS_LATE") <= 60, "31-60 days late")
         .when(F.col("AVG_DAYS_LATE") <= 90, "61-90 days late")
         .otherwise(">90 days late")
    )
)

# 14. Persist patient-level metrics
session.sql("TRUNCATE TABLE PATIENT_BEHAVIOR_METRICS").collect()
df_patient.write.save_as_table("PATIENT_BEHAVIOR_METRICS", mode="overwrite")

# 15. Group-level rollups
groupings = ["PATIENT_GROUP","ITEM_GROUP","INSURANCE","DAYS_LATE_BUCKET"]
for grp in groupings:
    session.sql(f"TRUNCATE TABLE BEHAVIOR_BY_{grp}").collect()
    df_grp = (
        df_patient
        .group_by(grp)
        .agg(
            F.avg("TENURE_DAYS").alias("AVG_TENURE_DAYS"),
            F.avg("RECENCY_DAYS").alias("AVG_RECENCY_DAYS"),
            F.avg("ORDERS_TOTAL").alias("AVG_FREQ_PER_PATIENT"),
            F.avg("TOTAL_REVENUE").alias("AVG_REV_PER_PATIENT"),
            F.avg("AVG_DAYS_BETWEEN").alias("AVG_DAYS_BETWEEN_ORDERS"),
            F.avg("AVG_DAYS_LATE").alias("AVG_DAYS_LATE"),
            F.avg("ON_TIME_RATE").alias("AVG_ON_TIME_RATE"),
            F.count("PATIENTID").alias("PATIENT_COUNT")
        )
    )
    df_grp.write.save_as_table(f"BEHAVIOR_BY_{grp}", mode="overwrite")

# 16. Monthly behavior trends (last 24 months)
start_date = today - timedelta(days=730)
monthly_trends = (
    order_intervals
    .with_column("MONTH", F.date_trunc("month", F.col("SERVICEDATEOFORDER")))
    .filter(F.col("MONTH") >= F.lit(start_date))
    .group_by("MONTH").agg(
        F.count_distinct("PATIENTID").alias("ACTIVE_PATIENTS"),
        F.count("ORDERNUMBER").alias("TOTAL_ORDERS"),
        F.avg("DAYS_AFTER_ELIGIBLE").alias("AVG_DAYS_LATE"),
        (F.sum("ON_TIME_FLAG")/F.count("ORDERNUMBER")).alias("ON_TIME_RATE"),
        F.sum("TOTALAMOUNT").alias("TOTAL_REVENUE")
    )
    .order_by("MONTH")
)
session.sql("TRUNCATE TABLE MONTHLY_BEHAVIOR_TRENDS").collect()
monthly_trends.write.save_as_table("MONTHLY_BEHAVIOR_TRENDS", mode="overwrite")

# 17. Close session
session.close()
```
